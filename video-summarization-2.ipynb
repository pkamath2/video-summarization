{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b848926-fb17-44f3-9cc9-e3201c26217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c72258b1-4ca6-4d4f-b6e8-d7eaced53d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/purnimakamath/opt/anaconda3/envs/video-summaries/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math, json, os\n",
    "import torch\n",
    "import itertools\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9d0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checknum(a):\n",
    "    try:\n",
    "        int(a)\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "48c344a9-8ba4-4067-8a9b-40880268099b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 79)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"videos/NUSFutureWork-Deepgram.json\") as f:\n",
    "    deepgram_json = json.load(f)\n",
    "f.close()\n",
    "\n",
    "transcript = deepgram_json['results']['channels'][0]['alternatives'][0]['transcript']\n",
    "paragraphs = deepgram_json['results']['channels'][0]['alternatives'][0]['paragraphs']\n",
    "sentences_obj = [_ for _ in list(itertools.chain(*[para['sentences'] for para in paragraphs['paragraphs']]))] # needed for start and end times\n",
    "sentences = [_['text'] for _ in list(itertools.chain(*[para['sentences'] for para in paragraphs['paragraphs']]))]\n",
    "sentence_lengths = [int((_['end']-_['start'])*1) for _ in list(itertools.chain(*[para['sentences'] for para in paragraphs['paragraphs']]))]\n",
    "#summary\n",
    "# script = ''\n",
    "# for sentence in sentences:\n",
    "#     script += sentence\n",
    "# print(script)\n",
    "\n",
    "len(sentences), len(sentence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27d11057-c03a-490a-8ea6-1bff83dd15c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ladies and gentlemen, please put your hands together to welcome our guest of honor, minister for education, mister Chan Chun Sing.\n",
      "A very good morning to guest of honor, minister for education, mister Chanchin Singh.\n",
      "Keynote speaker, professor James Landay.\n",
      "NUS president, professor Tan Eng Chai.\n",
      "Deputy president of academic affairs and provost, professor Aaron Tian.\n",
      "Distinguished guests, alumni, and partners here at NUSS and tuning in online.\n",
      "Welcome to Future Work 2.0, the second edition of the NUS Lifelong Learning Festival.\n",
      "My name is Joey, and I'm a proud alumna, a staff member of NUS, and your emcee for this morning.\n",
      "The theme for this year's conference is AI in action, and we are grateful that so many industry leaders and experts have generously offered their time to get today to share their invaluable experiences in this area.\n",
      "We are also grateful that you have taken the time to attend the conference, and we hope that you will leave with insights, connections, and inspiration for our future with AI.\n",
      "Before we begin, a quick safety and evacuation briefing.\n",
      "In case of an emergency, please evacuate through the exits behind the stage or at the back of the hall to the assembly area outside, and do not reenter the building until further instructions.\n",
      "Now let's get started.\n",
      "We would like to invite NUS president, professor Tan Eng Chai, to give the welcome address.\n",
      "Professor Tan, please.\n",
      "Minister for education, mister Chan Chun Sing, distinguished guests, colleagues, alumni, and friends, good morning.\n",
      "And I bid you a warm welcome to the second edition of the NUS Lifelong Learning Festival.\n",
      "The theme for this year's learning festival is Future Work 2.0, AI in Action.\n",
      "The emphasis is on action.\n",
      "Many of us have already heard much about what AI can do, its promise, and its perils.\n",
      "It may sound like a paradox, but AI is for real and in action, transforming work and industries.\n",
      "Today, we will have the privilege of hearing from industry leaders on how they are using AI in their organizations, what compels them to deploy AI, the changes AI has brought about, and how they are bringing their workforce on this new AI journey.\n",
      "We are in a watershed moment at the tops of an AI revolution.\n",
      "Some of us here, those with graying hairs, will recall a similar period nearly 40 years ago where personal computers came to the workplace, putting the power of computing into individual hands, replacing pen and paper, records, and typewriters.\n",
      "A decade or so later, the transformative power of the PC was taken to a whole new level by the emergence of the Internet.\n",
      "When confronted with the event of new technologies, we must be open, excited, and innovative about the opportunities that new technologies can bring.\n",
      "NUS recognizes that AI is a game changer.\n",
      "We are actively positioning ourselves to write the potential of AI.\n",
      "Now on the research front, we established the NUS AI Institute in March this year.\n",
      "And this brings together AI researchers from across the university to accelerate frontier AI research as well as to boost real world impact.\n",
      "This AI Institute will foster a vibrant ecosystem that promotes synergistic AI research and applications, as well as to grow the AI talent pool and to engage government as well as industry in partnerships.\n",
      "And these are also in the areas of education, healthcare, finance, sustainability, logistics, manufacturing, and so on and so forth.\n",
      "This institute will also conduct research on how to regulate and to safeguard transparency and accountability to address ethical concerns and risks associated with AI.\n",
      "NUS has also been proactively guiding and encouraging the integration of AI in our teaching and learning.\n",
      "So in February 2023 last year, NUS NUS crafted an interim policy, and this is the first of its kind among Singapore institutions to provide guidance, on staff use of AI and also how to manage student use of AI.\n",
      "And since the beginning of this year, the Center For Training, Learning, and Technology has been offering a range of AI workshops on topics such as using generative AI for course design, question generation and assessments.\n",
      "NUS has also formed, an AI community of practice.\n",
      "And this is to exchange ideas, share resources, promote best practices, and also set community standards for the use of AI in teaching and learning.\n",
      "So AI tools are also being rolled out across various aspects of our administration and operational work.\n",
      "NUS IT has built a generative AI or gen AI platform for our NUS community using retrieval augmented generation process and on models such as OpenAI GPT and, Google Gemini.\n",
      "Now this platform helps our staff to get answers for NUS specific questions, such as queries on NUS policies.\n",
      "And NUS IT has also worked with departments to use AI to improve productivity across a wide range of use cases.\n",
      "For example, using AI to assess appeals.\n",
      "And as part of learning and development, the Office of Human Resources has worked with faculty members to develop blended on the job training for NUS administrative staff in data literacy and AI.\n",
      "So I'm pleased to share that close to 5,000 admin staff have completed, the first level of data literacy course, as well as the first level of AI competency course.\n",
      "As one of Singapore's public universities, NUS has a responsibility to support the training needs of alumni and the wider Singapore workforce, and to help to ensure that we remain economically competitive.\n",
      "AI is rapidly evolving, and we seek to equip professionals with current and relevant knowledge, and also to build capacities in this area.\n",
      "To this end, NUS offers around 250 courses and 60 certificates that cover AI skills.\n",
      "Number of our master's degree programs include AI courses and skills.\n",
      "So we are currently developing 4 more, master's program that will have an explicit focus on AI, and that's scheduled to be launched next year.\n",
      "Since 2017, more than 30,000 learners have read AI related courses at NUS.\n",
      "So we have delivered AI training for many organizations including Singtel, Shell, NEC, MINDEF, and UOB.\n",
      "In May, we also invite NUS alumni to join our introductory online courses offered by AI Singapore.\n",
      "And these are in two aspects, AI for everyone and AI for industry.\n",
      "And over actually 100 alumni have responded to this invitation.\n",
      "We wish to have more actually.\n",
      "Besides AI, learners can explore a wide range of continuing education and training, or CET courses offered by NUS across many areas.\n",
      "We now offer more than 100 master's programs, 200 micro credentials, and a 1200 courses.\n",
      "Education is a continual process, and there's no date ends.\n",
      "Many of our CET courses are offered on a modular basis, and they are stackable.\n",
      "Should you wish to build towards, qualification, Learners can choose to broaden, to deepen, or to refresh your knowledge and skills.\n",
      "And we are committed to supporting learners, including senior alumni for whom we'll be launching a new program soon.\n",
      "To further encourage Singaporeans to engage in CET, I'm pleased to announce that NUS will be providing a 40% tuition fee rebate on more than 80 master's degree programs to all Singapore citizens and Singapore permanent residents.\n",
      "So we hope that this rebate will alleviate the cost considerations for learners and that you will be encouraged to learn new skills and develop yourselves further along your career journey.\n",
      "Many working professionals in Singapore see the importance of continuous learning.\n",
      "This was a finding from a large scale survey that NUS has commissioned in 2023.\n",
      "The survey also revealed that a key impediment to pursuing CET is the issue of cost.\n",
      "Thus, I hope that the announcement of the 40% fee rebate for over 80 masters courses serves as an impetus for Singaporeans and PRs to explore the many learning options and pathways at NUS.\n",
      "I also urge learners not to be immediately deterred by headline tuition fees, as they are eligible also for substantial subsidies for many of our CET courses that, NUS offers.\n",
      "And to help learners fit continuous learning in your schedules, a growing number of CET courses are being offered on a blended format, and some on online offerings.\n",
      "So this will help learners and give them even more flexibility in organizing their time and also commitments.\n",
      "In closing, let me share this quote from Karl Sharro.\n",
      "Humans doing the hard jobs on minimum wage while robots write poetry and pain is not the future I wanted.\n",
      "Now I certainly agree.\n",
      "Let us instead put the robots and AI to work, master the new technology, integrate it smartly into our work processes, let robots and AI superpower us at the workplace.\n",
      "Without much ado, I would like to thank the school of continuing and lifelong learning for putting this event together.\n",
      "I would also like to thank all speakers and participants for your support, and I wish everyone an enriching and enjoyable lifelong learning festival.\n",
      "Thank you.\n",
      "Thank you, Professor Tan.\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2e6fc0-a8c5-4777-9c0f-86e7a7523268",
   "metadata": {},
   "source": [
    "# Summarize this transcript \"<contents>\". In the summary, use very short sentences. Each sentence must be a distinct topic in the transcript. Do not use abbreviations and titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "090d9ac0-e4a9-4e81-acfa-88d378591603",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_gpt_summary =  \"The event welcomed attendees to the second National University of Singapore Lifelong Learning Festival, themed Future Work 2 point 0: AI in Action. The opening remarks emphasized the importance of embracing artificial intelligence's transformative potential across industries. The University’s President highlighted the growing impact of artificial intelligence, likening it to earlier technological revolutions like personal computers and the internet. The University has been proactive in integrating artificial intelligence across its programs. It launched the National University of Singapore AI Institute to foster research and collaborations with industry and government. The institution also developed policies and training initiatives to guide staff and students on using artificial intelligence in education, including workshops on generative AI for course design and assessment. Moreover, the University’s administrative departments use artificial intelligence to enhance productivity. Staff training in data literacy and artificial intelligence has reached thousands, preparing employees for AI-driven tasks. The University also supports lifelong learning through a wide selection of courses, certificates, and modular learning options in artificial intelligence and other fields. Recognizing the cost of education as a barrier, the University announced a 40% tuition fee rebate for Singaporeans and permanent residents on over 80 master’s programs. The speaker concluded with a call to use artificial intelligence to empower, rather than replace, human workers. The event closed with thanks to the School of Continuing and Lifelong Learning and all participants.\"\n",
    "# chat_gpt_summary = \"The event opened with a welcome for the Minister for Education, Chan Chun Sing. Joey, the emcee, introduced the NUS Lifelong Learning Festival, Future Work 2 point 0. This year's theme is AI in Action, emphasizing AI's practical applications. NUS President Tan Eng Chai highlighted AI's transformative impact on work. He noted the AI Institute's establishment for research and collaboration. NUS is integrating AI into education and administration. The Center for Teaching, Learning, and Technology offers AI workshops. NUS IT has developed a generative AI platform for staff queries. Over 5,000 administrative staff completed data and AI courses. NUS offers numerous AI-related courses for lifelong learning. A 40% tuition rebate on 80 master’s programs was announced for Singapore citizens and residents. Flexible course formats are available to support continuous education. Tan encouraged learning to leverage AI for productivity. He thanked organizers and participants for supporting the festival.\"\n",
    "chatgpt_summary_sentences = []\n",
    "\n",
    "for sentence in chat_gpt_summary.split(\".\"):\n",
    "    if len(sentence) > 0:\n",
    "        chatgpt_summary_sentences.append(sentence.strip()+\".\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dadf51c5-2be8-4e2e-9286-debdb16231a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The event welcomed attendees to the second National University of Singapore Lifelong Learning Festival, themed Future Work 2 point 0: AI in Action.',\n",
       " \"The opening remarks emphasized the importance of embracing artificial intelligence's transformative potential across industries.\",\n",
       " 'The University’s President highlighted the growing impact of artificial intelligence, likening it to earlier technological revolutions like personal computers and the internet.',\n",
       " 'The University has been proactive in integrating artificial intelligence across its programs.',\n",
       " 'It launched the National University of Singapore AI Institute to foster research and collaborations with industry and government.',\n",
       " 'The institution also developed policies and training initiatives to guide staff and students on using artificial intelligence in education, including workshops on generative AI for course design and assessment.',\n",
       " 'Moreover, the University’s administrative departments use artificial intelligence to enhance productivity.',\n",
       " 'Staff training in data literacy and artificial intelligence has reached thousands, preparing employees for AI-driven tasks.',\n",
       " 'The University also supports lifelong learning through a wide selection of courses, certificates, and modular learning options in artificial intelligence and other fields.',\n",
       " 'Recognizing the cost of education as a barrier, the University announced a 40% tuition fee rebate for Singaporeans and permanent residents on over 80 master’s programs.',\n",
       " 'The speaker concluded with a call to use artificial intelligence to empower, rather than replace, human workers.',\n",
       " 'The event closed with thanks to the School of Continuing and Lifelong Learning and all participants.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_summary_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2e4c98a-7ad4-4b2d-bfd5-e8553a3c6b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "644580b9-bd3c-4a94-84aa-91de5f46e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9dece4e8-758c-4851-9038-61cf1c0d1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_embeddings = model.encode(chatgpt_summary_sentences)\n",
    "sentences_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a94c120-cbfe-45b1-ad44-609fa51ed1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = model.similarity(chatgpt_embeddings, sentences_embeddings) # Not used\n",
    "for ind1, similarity in enumerate(similarities):\n",
    "    for ind2, s in enumerate(similarity):\n",
    "        # similarities[ind1][ind2] = s * sentence_lengths[ind2]# Dont do this. Sentence len is skewing up things.\n",
    "        similarities[ind1][ind2] = s \n",
    "\n",
    "cos = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "cos_similarities = []\n",
    "for chatgpt_embedding in chatgpt_embeddings:\n",
    "    chatgpt_sim = []\n",
    "    for ind, sentences_embedding in enumerate(sentences_embeddings):\n",
    "        # chatgpt_sim.append(cos(torch.from_numpy(chatgpt_embedding), torch.from_numpy(sentences_embedding)).numpy()*sentence_lengths[ind]) # Dont do this. Sentence len is skewing up things.\n",
    "        chatgpt_sim.append(cos(torch.from_numpy(chatgpt_embedding), torch.from_numpy(sentences_embedding)).numpy()*sentence_lengths[ind])\n",
    "    cos_similarities.append(chatgpt_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "377feda8-3659-46d7-8c6f-4c34222062ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similarities), len(cos_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47560adb-7204-4824-8631-2d1441b59deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The event welcomed attendees to the second National University of Singapore Lifelong Learning Festival, themed Future Work 2 point 0: AI in Action. ==> The theme for this year's learning festival is Future Work 2.0, AI in Action. tensor(0.7325) 7\n",
      "--------\n",
      "The opening remarks emphasized the importance of embracing artificial intelligence's transformative potential across industries. ==> It may sound like a paradox, but AI is for real and in action, transforming work and industries. tensor(0.6801) 8\n",
      "--------\n",
      "The University’s President highlighted the growing impact of artificial intelligence, likening it to earlier technological revolutions like personal computers and the internet. ==> And this brings together AI researchers from across the university to accelerate frontier AI research as well as to boost real world impact. tensor(0.6425) 12\n",
      "--------\n",
      "The University has been proactive in integrating artificial intelligence across its programs. ==> NUS has also been proactively guiding and encouraging the integration of AI in our teaching and learning. tensor(0.6053) 10\n",
      "--------\n",
      "It launched the National University of Singapore AI Institute to foster research and collaborations with industry and government. ==> This AI Institute will foster a vibrant ecosystem that promotes synergistic AI research and applications, as well as to grow the AI talent pool and to engage government as well as industry in partnerships. tensor(0.6432) 18\n",
      "--------\n",
      "The institution also developed policies and training initiatives to guide staff and students on using artificial intelligence in education, including workshops on generative AI for course design and assessment. ==> And since the beginning of this year, the Center For Training, Learning, and Technology has been offering a range of AI workshops on topics such as using generative AI for course design, question generation and assessments. tensor(0.7725) 19\n",
      "--------\n",
      "Moreover, the University’s administrative departments use artificial intelligence to enhance productivity. ==> And NUS IT has also worked with departments to use AI to improve productivity across a wide range of use cases. tensor(0.6097) 10\n",
      "--------\n",
      "Staff training in data literacy and artificial intelligence has reached thousands, preparing employees for AI-driven tasks. ==> So I'm pleased to share that close to 5,000 admin staff have completed, the first level of data literacy course, as well as the first level of AI competency course. tensor(0.6819) 16\n",
      "--------\n",
      "The University also supports lifelong learning through a wide selection of courses, certificates, and modular learning options in artificial intelligence and other fields. ==> Besides AI, learners can explore a wide range of continuing education and training, or CET courses offered by NUS across many areas. tensor(0.6216) 13\n",
      "--------\n",
      "Recognizing the cost of education as a barrier, the University announced a 40% tuition fee rebate for Singaporeans and permanent residents on over 80 master’s programs. ==> To further encourage Singaporeans to engage in CET, I'm pleased to announce that NUS will be providing a 40% tuition fee rebate on more than 80 master's degree programs to all Singapore citizens and Singapore permanent residents. tensor(0.7397) 25\n",
      "--------\n",
      "The speaker concluded with a call to use artificial intelligence to empower, rather than replace, human workers. ==> Let us instead put the robots and AI to work, master the new technology, integrate it smartly into our work processes, let robots and AI superpower us at the workplace. tensor(0.6129) 17\n",
      "--------\n",
      "The event closed with thanks to the School of Continuing and Lifelong Learning and all participants. ==> Without much ado, I would like to thank the school of continuing and lifelong learning for putting this event together. tensor(0.6591) 8\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(chatgpt_summary_sentences)):\n",
    "    print(chatgpt_summary_sentences[i], '==>', \\\n",
    "          sentences[np.argmax(similarities[i])], \\\n",
    "          similarities[i][np.argmax(similarities[i])], \\\n",
    "          sentence_lengths[np.argmax(similarities[i])])\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ed46c98-e391-4559-83a7-2947ee177e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 79, 79)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cos_similarities), len(chatgpt_summary_sentences), len(sentence_lengths), len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3e1fec81-f60e-4032-bc42-71151e693a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity = 30 #40 seconds | capacity\n",
    "\n",
    "#knapsack problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "69cf193a-1a4b-4ae9-87ae-dfadad0f20ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [] # sentences\n",
    "weights = [] # sentence lengths\n",
    "values = [] # similarities\n",
    "\n",
    "item_starts = [] #start and stop times in video\n",
    "item_ends = []\n",
    "\n",
    "for i in range(len(chatgpt_summary_sentences)):\n",
    "    items.append(sentences[np.argmax(similarities[i])])\n",
    "    weights.append(sentence_lengths[np.argmax(similarities[i])])\n",
    "    values.append(similarities[i][np.argmax(similarities[i])])\n",
    "\n",
    "    item_starts.append(sentences_obj[np.argmax(similarities[i])]['start'])\n",
    "    item_ends.append(sentences_obj[np.argmax(similarities[i])]['end'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4d9fc756-b54a-40b7-a4db-ee66489a8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(items)\n",
    "dp = [[0 for i in range(capacity+1)] for w in range(n+1)] #15 X 401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ef8303f5-b231-45d2-a073-2bceb247c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n+1):\n",
    "    for w in range(capacity+1):\n",
    "        if i==0 or w==0:\n",
    "            dp[i][w] = 0\n",
    "        elif weights[i-1] <= w:\n",
    "            dp[i][w] = max(values[i-1]+dp[i-1][w-weights[i-1]], dp[i-1][w])\n",
    "        else:\n",
    "            dp[i][w] = dp[i-1][w]\n",
    "    w = capacity\n",
    "    chosen_items = []\n",
    "\n",
    "    for i in range(n, 0, -1):\n",
    "        if dp[i][w] != dp[i-1][w]:\n",
    "            chosen_items.append(items[i-1])\n",
    "            w -= weights[i-1]\n",
    "    total_value = dp[n][capacity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "68f66897-3d71-4a89-8327-5932c2445766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"The theme for this year's learning festival is Future Work 2.0, AI in Action.\",\n",
       "  'It may sound like a paradox, but AI is for real and in action, transforming work and industries.',\n",
       "  'Without much ado, I would like to thank the school of continuing and lifelong learning for putting this event together.'],\n",
       " tensor(2.0718))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_items[::-1], total_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1912863f-356a-4dd2-812c-b53cf6e77bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a58e9-7f29-47b5-99aa-73118009ecf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3d58dcfe-d858-4acf-bbd5-5b3506cb4b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25, '25/1')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe = ffmpeg.probe('videos/NUS FutureWork.mp4')\n",
    "video_info = next(s for s in probe['streams'] if s['codec_type'] == 'video')\n",
    "fps = int(video_info['r_frame_rate'].split('/')[0])\n",
    "fps, video_info['r_frame_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "be3fb183-9f47-4c8b-a6e6-42c51f0b3699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4603.625 4796.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "ffmpeg version 4.1.4 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with Apple LLVM version 10.0.1 (clang-1001.0.46.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.1.4_1 --enable-shared --enable-pthreads --enable-version3 --enable-avresample --cc=clang --host-cflags='-I/Library/Java/JavaVirtualMachines/adoptopenjdk-12.0.1.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/adoptopenjdk-12.0.1.jdk/Contents/Home/include/darwin' --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libmp3lame --enable-libopus --enable-librubberband --enable-libsnappy --enable-libtesseract --enable-libtheora --enable-libvorbis --enable-libvpx --enable-libx264 --enable-libx265 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librtmp --enable-libspeex --enable-videotoolbox --disable-libjack --disable-indev=jack --enable-libaom --enable-libsoxr\n",
      "  libavutil      56. 22.100 / 56. 22.100\n",
      "  libavcodec     58. 35.100 / 58. 35.100\n",
      "  libavformat    58. 20.100 / 58. 20.100\n",
      "  libavdevice    58.  5.100 / 58.  5.100\n",
      "  libavfilter     7. 40.101 /  7. 40.101\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  3.100 /  5.  3.100\n",
      "  libswresample   3.  3.100 /  3.  3.100\n",
      "  libpostproc    55.  3.100 / 55.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'videos/NUS FutureWork.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.45.100\n",
      "  Duration: 00:15:42.32, start: 0.000000, bitrate: 1787 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 1650 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 130 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> trim\n",
      "  Stream #0:1 (aac) -> atrim\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x7f7b80009400] using SAR=1/1\n",
      "[libx264 @ 0x7f7b80009400] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x7f7b80009400] profile High, level 4.0\n",
      "[libx264 @ 0x7f7b80009400] 264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=24 lookahead_threads=4 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'videos/output_0.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.20.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.35.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], q=-1--1, 25 fps, 12800 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.35.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=   27 fps=6.0 q=0.0 size=       0kB time=00:00:01.64 bitrate=   0.2kbits/s speed=0.364x    frame=   78 fps= 16 q=28.0 size=       0kB time=00:00:03.66 bitrate=   0.1kbits/s speed=0.729x    frame=  127 fps= 23 q=28.0 size=     256kB time=00:00:05.65 bitrate= 371.0kbits/s speed=1.02x    frame=  173 fps= 29 q=28.0 size=     768kB time=00:00:07.46 bitrate= 842.7kbits/s speed=1.24x    frame=  193 fps= 29 q=-1.0 Lsize=    1463kB time=00:00:07.70 bitrate=1556.0kbits/s speed=1.15x    \n",
      "video:1335kB audio:121kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.488853%\n",
      "[aac @ 0x7f7b80008200] Qavg: 238.000\n",
      "[libx264 @ 0x7f7b80009400] frame I:1     Avg QP:15.68  size: 27136\n",
      "[libx264 @ 0x7f7b80009400] frame P:49    Avg QP:16.92  size: 14540\n",
      "[libx264 @ 0x7f7b80009400] frame B:143   Avg QP:20.65  size:  4380\n",
      "[libx264 @ 0x7f7b80009400] consecutive B-frames:  1.0%  0.0%  1.6% 97.4%\n",
      "[libx264 @ 0x7f7b80009400] mb I  I16..4: 35.5% 61.0%  3.5%\n",
      "[libx264 @ 0x7f7b80009400] mb P  I16..4:  4.9% 14.5%  0.4%  P16..4: 21.5%  5.1%  1.5%  0.0%  0.0%    skip:52.2%\n",
      "[libx264 @ 0x7f7b80009400] mb B  I16..4:  0.4%  0.6%  0.0%  B16..8: 20.1%  1.3%  0.1%  direct: 3.3%  skip:74.2%  L0:48.1% L1:48.7% BI: 3.3%\n",
      "[libx264 @ 0x7f7b80009400] 8x8 transform intra:70.8% inter:81.8%\n",
      "[libx264 @ 0x7f7b80009400] coded y,uvDC,uvAC intra: 13.5% 15.6% 2.8% inter: 3.1% 5.6% 0.0%\n",
      "[libx264 @ 0x7f7b80009400] i16 v,h,dc,p: 38% 44%  5% 14%\n",
      "[libx264 @ 0x7f7b80009400] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 24% 15% 52%  1%  1%  2%  1%  1%  1%\n",
      "[libx264 @ 0x7f7b80009400] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 27% 20% 19%  5%  8%  7%  6%  4%  3%\n",
      "[libx264 @ 0x7f7b80009400] i8c dc,h,v,p: 66% 18% 15%  1%\n",
      "[libx264 @ 0x7f7b80009400] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x7f7b80009400] ref P L0: 60.6%  9.1% 22.1%  8.2%\n",
      "[libx264 @ 0x7f7b80009400] ref B L0: 84.6% 12.6%  2.8%\n",
      "[libx264 @ 0x7f7b80009400] ref B L1: 96.2%  3.8%\n",
      "[libx264 @ 0x7f7b80009400] kb/s:1415.41\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5089.49975 5298.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.1.4 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with Apple LLVM version 10.0.1 (clang-1001.0.46.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.1.4_1 --enable-shared --enable-pthreads --enable-version3 --enable-avresample --cc=clang --host-cflags='-I/Library/Java/JavaVirtualMachines/adoptopenjdk-12.0.1.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/adoptopenjdk-12.0.1.jdk/Contents/Home/include/darwin' --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libmp3lame --enable-libopus --enable-librubberband --enable-libsnappy --enable-libtesseract --enable-libtheora --enable-libvorbis --enable-libvpx --enable-libx264 --enable-libx265 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librtmp --enable-libspeex --enable-videotoolbox --disable-libjack --disable-indev=jack --enable-libaom --enable-libsoxr\n",
      "  libavutil      56. 22.100 / 56. 22.100\n",
      "  libavcodec     58. 35.100 / 58. 35.100\n",
      "  libavformat    58. 20.100 / 58. 20.100\n",
      "  libavdevice    58.  5.100 / 58.  5.100\n",
      "  libavfilter     7. 40.101 /  7. 40.101\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  3.100 /  5.  3.100\n",
      "  libswresample   3.  3.100 /  3.  3.100\n",
      "  libpostproc    55.  3.100 / 55.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'videos/NUS FutureWork.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.45.100\n",
      "  Duration: 00:15:42.32, start: 0.000000, bitrate: 1787 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 1650 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 130 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> trim\n",
      "  Stream #0:1 (aac) -> atrim\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x7f906000d400] using SAR=1/1\n",
      "[libx264 @ 0x7f906000d400] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x7f906000d400] profile High, level 4.0\n",
      "[libx264 @ 0x7f906000d400] 264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=24 lookahead_threads=4 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'videos/output_1.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.20.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.35.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], q=-1--1, 25 fps, 12800 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.35.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    9 fps=2.0 q=0.0 size=       0kB time=00:00:00.89 bitrate=   0.4kbits/s speed=0.199x    frame=   62 fps= 12 q=0.0 size=       0kB time=00:00:03.02 bitrate=   0.1kbits/s speed=0.604x    frame=  110 fps= 20 q=28.0 size=     256kB time=00:00:04.97 bitrate= 422.0kbits/s speed=0.901x    frame=  162 fps= 27 q=28.0 size=     512kB time=00:00:07.04 bitrate= 595.8kbits/s speed=1.17x    frame=  209 fps= 30 q=-1.0 Lsize=    1470kB time=00:00:08.36 bitrate=1440.2kbits/s speed=1.21x    \n",
      "video:1330kB audio:132kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.519376%\n",
      "[aac @ 0x7f906000a000] Qavg: 286.472\n",
      "[libx264 @ 0x7f906000d400] frame I:1     Avg QP:14.39  size: 30430\n",
      "[libx264 @ 0x7f906000d400] frame P:53    Avg QP:17.01  size: 13645\n",
      "[libx264 @ 0x7f906000d400] frame B:155   Avg QP:21.10  size:  3922\n",
      "[libx264 @ 0x7f906000d400] consecutive B-frames:  1.0%  0.0%  1.4% 97.6%\n",
      "[libx264 @ 0x7f906000d400] mb I  I16..4: 56.0% 39.4%  4.6%\n",
      "[libx264 @ 0x7f906000d400] mb P  I16..4:  4.9% 12.7%  0.3%  P16..4: 21.4%  5.1%  1.7%  0.0%  0.0%    skip:53.9%\n",
      "[libx264 @ 0x7f906000d400] mb B  I16..4:  0.3%  0.5%  0.0%  B16..8: 20.2%  1.1%  0.1%  direct: 3.0%  skip:74.7%  L0:48.3% L1:49.1% BI: 2.6%\n",
      "[libx264 @ 0x7f906000d400] 8x8 transform intra:67.0% inter:81.1%\n",
      "[libx264 @ 0x7f906000d400] coded y,uvDC,uvAC intra: 11.1% 15.4% 3.2% inter: 3.0% 5.6% 0.0%\n",
      "[libx264 @ 0x7f906000d400] i16 v,h,dc,p: 38% 45%  3% 13%\n",
      "[libx264 @ 0x7f906000d400] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 21% 16% 58%  1%  1%  1%  1%  1%  1%\n",
      "[libx264 @ 0x7f906000d400] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 25% 20%  4%  7%  6%  6%  4%  3%\n",
      "[libx264 @ 0x7f906000d400] i8c dc,h,v,p: 64% 20% 15%  1%\n",
      "[libx264 @ 0x7f906000d400] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x7f906000d400] ref P L0: 60.0%  9.0% 22.7%  8.4%\n",
      "[libx264 @ 0x7f906000d400] ref B L0: 85.0% 12.5%  2.5%\n",
      "[libx264 @ 0x7f906000d400] ref B L1: 95.3%  4.7%\n",
      "[libx264 @ 0x7f906000d400] kb/s:1302.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13425.499 13828.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "ffmpeg version 4.1.4 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with Apple LLVM version 10.0.1 (clang-1001.0.46.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.1.4_1 --enable-shared --enable-pthreads --enable-version3 --enable-avresample --cc=clang --host-cflags='-I/Library/Java/JavaVirtualMachines/adoptopenjdk-12.0.1.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/adoptopenjdk-12.0.1.jdk/Contents/Home/include/darwin' --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libmp3lame --enable-libopus --enable-librubberband --enable-libsnappy --enable-libtesseract --enable-libtheora --enable-libvorbis --enable-libvpx --enable-libx264 --enable-libx265 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librtmp --enable-libspeex --enable-videotoolbox --disable-libjack --disable-indev=jack --enable-libaom --enable-libsoxr\n",
      "  libavutil      56. 22.100 / 56. 22.100\n",
      "  libavcodec     58. 35.100 / 58. 35.100\n",
      "  libavformat    58. 20.100 / 58. 20.100\n",
      "  libavdevice    58.  5.100 / 58.  5.100\n",
      "  libavfilter     7. 40.101 /  7. 40.101\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  3.100 /  5.  3.100\n",
      "  libswresample   3.  3.100 /  3.  3.100\n",
      "  libpostproc    55.  3.100 / 55.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'videos/NUS FutureWork.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.45.100\n",
      "  Duration: 00:15:42.32, start: 0.000000, bitrate: 1787 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 1650 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 130 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> trim\n",
      "  Stream #0:1 (aac) -> atrim\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x7fb61980d400] using SAR=1/1\n",
      "[libx264 @ 0x7fb61980d400] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x7fb61980d400] profile High, level 4.0\n",
      "[libx264 @ 0x7fb61980d400] 264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=24 lookahead_threads=4 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'videos/output_2.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.20.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.35.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], q=-1--1, 25 fps, 12800 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.35.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=   59 fps=5.1 q=0.0 size=       0kB time=00:00:02.94 bitrate=   0.1kbits/s speed=0.255x    frame=  115 fps=9.6 q=28.0 size=     256kB time=00:00:05.16 bitrate= 406.3kbits/s speed=0.429x    frame=  169 fps= 13 q=28.0 size=     512kB time=00:00:07.31 bitrate= 573.3kbits/s speed=0.581x    frame=  222 fps= 17 q=28.0 size=    1024kB time=00:00:09.45 bitrate= 887.7kbits/s speed=0.722x    frame=  278 fps= 20 q=28.0 size=    1280kB time=00:00:11.66 bitrate= 898.6kbits/s speed=0.858x    frame=  332 fps= 24 q=28.0 size=    1792kB time=00:00:13.84 bitrate=1060.3kbits/s speed=0.98x    frame=  383 fps= 26 q=28.0 size=    2304kB time=00:00:15.87 bitrate=1189.2kbits/s speed=1.09x    frame=  403 fps= 26 q=-1.0 Lsize=    2952kB time=00:00:16.12 bitrate=1499.3kbits/s speed=1.05x    \n",
      "video:2681kB audio:258kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.455155%\n",
      "[aac @ 0x7fb61980c200] Qavg: 279.156\n",
      "[libx264 @ 0x7fb61980d400] frame I:2     Avg QP:14.61  size: 35432\n",
      "[libx264 @ 0x7fb61980d400] frame P:102   Avg QP:17.09  size: 14192\n",
      "[libx264 @ 0x7fb61980d400] frame B:299   Avg QP:21.56  size:  4100\n",
      "[libx264 @ 0x7fb61980d400] consecutive B-frames:  0.5%  1.5%  0.7% 97.3%\n",
      "[libx264 @ 0x7fb61980d400] mb I  I16..4: 36.6% 58.1%  5.4%\n",
      "[libx264 @ 0x7fb61980d400] mb P  I16..4:  4.7% 11.5%  0.4%  P16..4: 21.9%  5.3%  1.8%  0.0%  0.0%    skip:54.4%\n",
      "[libx264 @ 0x7fb61980d400] mb B  I16..4:  0.3%  0.6%  0.0%  B16..8: 20.6%  1.2%  0.1%  direct: 2.1%  skip:75.0%  L0:47.8% L1:49.6% BI: 2.7%\n",
      "[libx264 @ 0x7fb61980d400] 8x8 transform intra:67.2% inter:81.0%\n",
      "[libx264 @ 0x7fb61980d400] coded y,uvDC,uvAC intra: 14.6% 16.1% 3.1% inter: 3.2% 4.8% 0.0%\n",
      "[libx264 @ 0x7fb61980d400] i16 v,h,dc,p: 33% 47%  4% 15%\n",
      "[libx264 @ 0x7fb61980d400] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 22% 16% 53%  1%  1%  2%  1%  2%  2%\n",
      "[libx264 @ 0x7fb61980d400] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 26% 23% 18%  4%  8%  7%  6%  5%  4%\n",
      "[libx264 @ 0x7fb61980d400] i8c dc,h,v,p: 68% 17% 14%  1%\n",
      "[libx264 @ 0x7fb61980d400] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x7fb61980d400] ref P L0: 59.7%  8.9% 22.7%  8.8%\n",
      "[libx264 @ 0x7fb61980d400] ref B L0: 82.1% 14.9%  3.0%\n",
      "[libx264 @ 0x7fb61980d400] ref B L1: 96.0%  4.0%\n",
      "[libx264 @ 0x7fb61980d400] kb/s:1361.91\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22805.625 23024.12425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.1.4 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with Apple LLVM version 10.0.1 (clang-1001.0.46.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.1.4_1 --enable-shared --enable-pthreads --enable-version3 --enable-avresample --cc=clang --host-cflags='-I/Library/Java/JavaVirtualMachines/adoptopenjdk-12.0.1.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/adoptopenjdk-12.0.1.jdk/Contents/Home/include/darwin' --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libmp3lame --enable-libopus --enable-librubberband --enable-libsnappy --enable-libtesseract --enable-libtheora --enable-libvorbis --enable-libvpx --enable-libx264 --enable-libx265 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librtmp --enable-libspeex --enable-videotoolbox --disable-libjack --disable-indev=jack --enable-libaom --enable-libsoxr\n",
      "  libavutil      56. 22.100 / 56. 22.100\n",
      "  libavcodec     58. 35.100 / 58. 35.100\n",
      "  libavformat    58. 20.100 / 58. 20.100\n",
      "  libavdevice    58.  5.100 / 58.  5.100\n",
      "  libavfilter     7. 40.101 /  7. 40.101\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  3.100 /  5.  3.100\n",
      "  libswresample   3.  3.100 /  3.  3.100\n",
      "  libpostproc    55.  3.100 / 55.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'videos/NUS FutureWork.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.45.100\n",
      "  Duration: 00:15:42.32, start: 0.000000, bitrate: 1787 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 1650 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 130 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> trim\n",
      "  Stream #0:1 (aac) -> atrim\n",
      "  concat:out:a0 -> Stream #0:0 (aac)\n",
      "  concat:out:v0 -> Stream #0:1 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x7fb92300e200] using SAR=1/1\n",
      "[libx264 @ 0x7fb92300e200] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x7fb92300e200] profile High, level 4.0\n",
      "[libx264 @ 0x7fb92300e200] 264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=24 lookahead_threads=4 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'videos/output_3.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.20.100\n",
      "    Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.35.100 aac\n",
      "    Stream #0:1: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], q=-1--1, 25 fps, 12800 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.35.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=    0 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    frame=   16 fps=0.9 q=0.0 size=       0kB time=00:00:01.19 bitrate=   0.3kbits/s speed=0.0662x    frame=   78 fps=4.2 q=28.0 size=       0kB time=00:00:03.66 bitrate=   0.1kbits/s speed=0.198x    frame=  131 fps=6.9 q=28.0 size=     256kB time=00:00:05.78 bitrate= 362.8kbits/s speed=0.303x    frame=  183 fps=9.4 q=28.0 size=     768kB time=00:00:07.87 bitrate= 799.3kbits/s speed=0.402x    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.91997999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  219 fps= 11 q=-1.0 Lsize=    1546kB time=00:00:08.74 bitrate=1447.9kbits/s speed=0.429x    \n",
      "video:1400kB audio:138kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.512210%\n",
      "[aac @ 0x7fb92300ae00] Qavg: 235.083\n",
      "[libx264 @ 0x7fb92300e200] frame I:1     Avg QP:16.11  size: 29491\n",
      "[libx264 @ 0x7fb92300e200] frame P:55    Avg QP:17.41  size: 13631\n",
      "[libx264 @ 0x7fb92300e200] frame B:163   Avg QP:21.87  size:  4013\n",
      "[libx264 @ 0x7fb92300e200] consecutive B-frames:  0.5%  0.0%  2.7% 96.8%\n",
      "[libx264 @ 0x7fb92300e200] mb I  I16..4: 25.4% 70.4%  4.2%\n",
      "[libx264 @ 0x7fb92300e200] mb P  I16..4:  4.6% 11.7%  0.3%  P16..4: 23.4%  5.3%  1.5%  0.0%  0.0%    skip:53.2%\n",
      "[libx264 @ 0x7fb92300e200] mb B  I16..4:  0.3%  0.6%  0.0%  B16..8: 22.1%  1.2%  0.1%  direct: 1.8%  skip:73.9%  L0:49.1% L1:48.5% BI: 2.4%\n",
      "[libx264 @ 0x7fb92300e200] 8x8 transform intra:70.0% inter:84.3%\n",
      "[libx264 @ 0x7fb92300e200] coded y,uvDC,uvAC intra: 13.9% 13.5% 2.2% inter: 3.2% 4.4% 0.0%\n",
      "[libx264 @ 0x7fb92300e200] i16 v,h,dc,p: 29% 49%  5% 17%\n",
      "[libx264 @ 0x7fb92300e200] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 22% 16% 54%  1%  1%  1%  2%  1%  1%\n",
      "[libx264 @ 0x7fb92300e200] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 20% 19%  3%  9%  6%  7%  4%  3%\n",
      "[libx264 @ 0x7fb92300e200] i8c dc,h,v,p: 73% 14% 12%  1%\n",
      "[libx264 @ 0x7fb92300e200] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x7fb92300e200] ref P L0: 58.3%  8.9% 23.6%  9.2%\n",
      "[libx264 @ 0x7fb92300e200] ref B L0: 83.2% 13.6%  3.2%\n",
      "[libx264 @ 0x7fb92300e200] ref B L1: 94.9%  5.1%\n",
      "[libx264 @ 0x7fb92300e200] kb/s:1308.94\n"
     ]
    }
   ],
   "source": [
    "input_file = ffmpeg.input('videos/NUS FutureWork.mp4')\n",
    "\n",
    "\n",
    "tot = 0\n",
    "for i in range(len(chosen_items)):\n",
    "    snip = sentences_obj[sentences.index(chosen_items[::-1][i])]\n",
    "    tot += (snip['end']-snip['start'])\n",
    "    print(snip['start']*fps, snip['end']*fps)\n",
    "\n",
    "    out_temp = 'videos/output_'+str(i)+'.mp4'\n",
    "    if os.path.exists(out_temp):\n",
    "        os.remove(out_temp)\n",
    "        \n",
    "    pts='PTS-STARTPTS'\n",
    "    vid = input_file.trim(start=snip['start'], end=snip['end']).setpts(pts)\n",
    "    aud = (input_file\n",
    "          .filter_('atrim', start=snip['start'], end=snip['end'])\n",
    "          .filter_('asetpts', pts))\n",
    "    \n",
    "    vid_aud = ffmpeg.concat(vid, aud, v=1, a=1)\n",
    "    output_file = ffmpeg.output(vid_aud, out_temp, format='mp4')\n",
    "    ffmpeg.run(output_file)\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823b36c-2b3c-4905-ae89-831ce2bc42a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6bcb92c0-91d2-42d3-b083-87cd364e68a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg  -i videos/output_0.mp4 -i videos/output_1.mp4 -i videos/output_2.mp4 -i videos/output_3.mp4 -filter_complex \"[0:v][0:a][1:v][1:a][2:v][2:a][3:v][3:a]concat=n=4:v=1:a=1\" -vsync vfr videos/output_final.mp4\n"
     ]
    }
   ],
   "source": [
    "final_out = 'videos/output_final.mp4'\n",
    "if os.path.exists(final_out):\n",
    "    os.remove(final_out)\n",
    "\n",
    "str_command = 'ffmpeg '\n",
    "str_command_args = ' -filter_complex \"'\n",
    "for i in range(len(chosen_items)):\n",
    "    str_command += ' -i videos/output_'+str(i)+'.mp4'\n",
    "    str_command_args += '['+str(i)+':v]['+str(i)+':a]'\n",
    "\n",
    "str_command_args += 'concat=n='+str(len(chosen_items))+':v=1:a=1\" -vsync vfr '+final_out\n",
    "str_command += str_command_args\n",
    "\n",
    "print(str_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951db2ec-82b9-4f32-b8b3-4f56a1c22b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781a71a-e8e8-47a8-b89f-e38bcbf3748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg -i video1.mp4 -i video2.mp4 -filter_complex \"[0:v][0:a][1:v][1:a]concat=n=2:v=1:a=1\" -vsync vfr output.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2181ee69-51c1-4d4d-9ccf-835f01d5bc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a9de441a-b0da-45a0-8647-acf82ec61f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[77, 56, 135, 27, 187, 105, 195, 186, 161, 130, 255, 152, 63, 116]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "28ddf48a-a870-444b-bfe8-7145f9211b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printknapSack(W, wt, val, n):\n",
    "    K = [[0 for w in range(W + 1)]\n",
    "            for i in range(n + 1)]\n",
    "             \n",
    "    # Build table K[][] in bottom\n",
    "    # up manner\n",
    "    for i in range(n + 1):\n",
    "        for w in range(W + 1):\n",
    "            if i == 0 or w == 0:\n",
    "                K[i][w] = 0\n",
    "            elif wt[i - 1] <= w:\n",
    "                K[i][w] = max(val[i - 1] \n",
    "                  + K[i - 1][w - wt[i - 1]],\n",
    "                               K[i - 1][w])\n",
    "            else:\n",
    "                K[i][w] = K[i - 1][w]\n",
    " \n",
    "    # stores the result of Knapsack\n",
    "    res = K[n][W]\n",
    "    print(res)\n",
    "     \n",
    "    w = W\n",
    "    for i in range(n, 0, -1):\n",
    "        if res <= 0:\n",
    "            break\n",
    "        # either the result comes from the\n",
    "        # top (K[i-1][w]) or from (val[i-1]\n",
    "        # + K[i-1] [w-wt[i-1]]) as in Knapsack\n",
    "        # table. If it comes from the latter\n",
    "        # one/ it means the item is included.\n",
    "        if res == K[i - 1][w]:\n",
    "            continue\n",
    "        else:\n",
    " \n",
    "            # This item is included.\n",
    "            print(wt[i - 1], i-1)\n",
    "             \n",
    "            # Since this weight is included\n",
    "            # its value is deducted\n",
    "            res = res - val[i - 1]\n",
    "            w = w - wt[i - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2109c2fb-f769-4bc2-840c-e7a2fa2f586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7838)\n",
      "130 9\n",
      "105 5\n",
      "27 3\n",
      "135 2\n",
      "56 1\n"
     ]
    }
   ],
   "source": [
    "printknapSack(summary_length, weights, values, len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a5c8a5ae-017d-4406-aa45-2690c478b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = []\n",
    "\n",
    "for i in range(len(chatgpt_summary_sentences)+1):\n",
    "    row = []\n",
    "    for j in range(summary_length+1):\n",
    "        row.append(0)\n",
    "    dp.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "17e0e00b-ff54-4795-a624-63483439f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(chatgpt_summary_sentences)+1):\n",
    "    for j in range(1, summary_length+1):\n",
    "        maxValWithoutCurr = dp[i - 1][j]\n",
    "        if j >= weights[i-1]:\n",
    "            remaining_capacity = j-weights[i-1]\n",
    "            dp[i][j] = values[i-1] + dp[i-1][remaining_capacity]\n",
    "            \n",
    "        dp[i][j] = max(dp[i][j], maxValWithoutCurr)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f8c23237-87be-4578-bfaa-3d2829edca57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(6.7716),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(6.8435),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4186),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4508),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(7.4905),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978),\n",
       " tensor(8.0978)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6778a-0e71-40eb-9836-e2efdf823179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bdd336-4a56-4cf5-a10b-6071f289c1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18cd3a1-ec63-4d0f-9730-bb75aebd64aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac14fc-54e3-4c90-87c1-2c12bbf18009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f50c0-e15c-40cf-8ac9-f4efd069a9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5142932-5b5f-4a58-960d-0933dda5e660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2f5880f-de06-453e-b191-61b0507a888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the memoization approach of\n",
    "# 0 / 1 Knapsack in Python in simple\n",
    "# we can say recursion + memoization = DP\n",
    "def knapsack(wt, val, W, n):\n",
    "\n",
    "    # base conditions\n",
    "    if n == 0 or W == 0:\n",
    "        return 0\n",
    "    if t[n][W] != -1:\n",
    "        return t[n][W]\n",
    "\n",
    "    # choice diagram code\n",
    "    if wt[n-1] <= W:\n",
    "        t[n][W] = max(\n",
    "            val[n-1] + knapsack(\n",
    "                wt, val, W-wt[n-1], n-1),\n",
    "            knapsack(wt, val, W, n-1))\n",
    "        return t[n][W]\n",
    "    elif wt[n-1] > W:\n",
    "        t[n][W] = knapsack(wt, val, W, n-1)\n",
    "        return t[n][W]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a4aaba2-7fe8-4f11-a493-4f77ecbad47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 51)\n",
      "220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[-1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1],\n",
       " [-1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  60,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  60,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  60],\n",
       " [-1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  100,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  160],\n",
       " [-1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  220]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Driver code\n",
    "\n",
    "profit = [60, 100, 120]\n",
    "weight = [10, 20, 30]\n",
    "W = 50\n",
    "n = len(profit)\n",
    "\n",
    "# We initialize the matrix with -1 at first.\n",
    "t = [[-1 for i in range(W + 1)] for j in range(n + 1)]\n",
    "print(np.array(t).shape)\n",
    "print(knapsack(weight, profit, W, n))\n",
    "t\n",
    "# This code is contributed by Prosun Kumar Sarkar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17420f3-d3d6-44d8-a2b0-b447d573e377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264ad40-56ac-4bd0-9c08-33a22b8ad24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cd7631-b21f-4101-a63e-e2db778e1f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6409ef89-b683-4e93-abfb-952e247f979c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd09170-925b-4f55-8c9b-6c417a06e573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5efe13d-1a3c-425f-ac59-a05de76b672f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0335438f-b189-4de5-8035-5bb5d0afb866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72c872-fa46-4598-bce0-82dc3964c8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6653a84a-bcce-40d1-bae4-a42c468a02d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ca963-2613-4844-b4e4-1a51866cbbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8609bdf-0d1e-4359-ae9f-ff03feb8f559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f74dea5b-9fd5-463a-9588-a0b676ab0782",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_srt_sentences = []\n",
    "for l in srt_sentences:\n",
    "    l_ = l.replace('\\n','')\n",
    "    if l_ == '':\n",
    "        continue \n",
    "    \n",
    "    if '-->' not in l_:\n",
    "        if checknum(l_):\n",
    "            continue\n",
    "        filtered_srt_sentences.append(l_)\n",
    "        \n",
    "final_script = ' '.join(filtered_srt_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fcf3be20-75e9-42ab-8f62-92abfd7ccebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ladies and gentlemen. Please put your hand to gather to welcome all guest of owner Minister for education Mr. Chan Chun Seang A very good morning to gasthof owner Minister for education, Mr. Chan Chee Seng, Keynote Speaker Prof James Lander and Yours President Prof Tan Eng Chai, Deputy President of Academic Affairs and Provost, Prof Aren't and Distinguished Guest, Alumni and Partners Here are Nurses and tuning in online Welcome to future works to point to the second edition of the nus lifelong learning festival. My name is jawi and a proud ulama staff member of nus and ummc for this morning. The theme for this years conference is a infection and we are grateful that so many industry leaders and experts have the general sale of their time today to share their invaluable experiences in this area. We are so grateful that you have taken the time to attend the conference and we hope that you will live with the insights connections and inspiration for our future wife. I. Before we begin a quick safety and evacuation briefing. In case of emergency Please evacuate to dxd behind the state. Or at the back of the hall to the assembly earlier outside and do not enter the building and further instructions. Now let's get started. We would like to invite NS President Prof Tan Eng Chai to give the Welcome Actress Thanks. Detective for Education, Mr. Chan Chuncheon, the Guest, Colleges Alumni and Friends. Good morning and I bet you a warm welcome to the second edition of the nus lifelong learning table. The theme for this year's learning Festival is future work to point zero i in action. The emphasis is on action. Many of us have already heard much about what I can do as promise and as parrots may sound like a paradox but i is for real and in action. Transforming Works and Industries today. We will have the privilege of hearing from industry leaders on how they are using ai in their organizations with complex them to deploy. The changes are as broad about and how They are bringing the workforce on this new ai journey. We are in the watershed moment at the cap of ai revolution. Some of US here to wave Grand Heroes will require similar period. Nearly forty years ago where personal computers came to the workplace Putting the power of computing into individual hands replacing Panama, Paper Records and type writer's jacket or show later. The transformative power of the PC Worlds attached to a whole new level by the emergence of the internet. Prank could granted with the advantage of New Technologies. We must be open excited and innovative about the opportunities that new technologies can bring and us recognizes that eye is a game changer. We are actively positioning ourselves to right the potential of ai On the Research Front. We established the US a Institute in March. This year and this brings together I Researchers from across the university to accelerate Frontier I research as well as to boost real World Impact. They say Institut of Forster a vibrant ecosystem that promotes synergistic A research and applications as well as to grow the talent pool And to engage the Goverment excellence industry in Partnerships. And this also in the areas of education Healthcare finance, Sustainability logistics magnet factoring and so on and so forth. This institute will also conduct research on how to regulate And to safeguard Transparency and Accountability. To address etika concerns and risk associated with I And us has also been proactive like guiding and encouraging The integration of aI In our teaching and Learning. So in February twenty twenty last year end up and guess crafted end interim policy and this is a first of its scene Singapore institutions to provide guidance on staff uses of a while and also how to manage students use of a high end. since the beginning of this year The center for training learning and technology has been offering a range of a workshops on topics such as using generative a for cost design question generation and assessments and use it as to form a community of practice and this is to exchange ideas Share resources promote best practices and also set community standards for the use of ai in teaching and learning. So i choose also being rode out across various aspects of our penetration and operational work and use it as both generative ai of a platform for our us community using retrieval, augmented generation process and all model such as open ai ppt and Google jamani This platform helps our staff to get answers for and use specific questions such as quarry his own and us policies and and use it as also works department's to use a life to improve productivity across a wide range of use cases. For example, using ai to access pupils and as part of learning and development. The office of human resources has work with faculty members to develop blended on the job training for US administrative staff in data literacy and I some pleased to share that close to five thousand admins staff have completed the first level of data literacy course as well as the first level of ai competency course\""
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ae6c7-2195-457a-ae6a-62ec69ad9cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "67f0a465-bf8b-4737-b026-53951e82e56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sentences = []\n",
    "\n",
    "for sentence in final_script.split(\".\"):\n",
    "    final_sentences.append(sentence.strip()+\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ef6a39aa-1791-479e-8e7f-25d05bfc60d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ladies and gentlemen.',\n",
       " 'Please put your hand to gather to welcome all guest of owner Minister for education Mr.',\n",
       " 'Chan Chun Seang A very good morning to gasthof owner Minister for education, Mr.',\n",
       " \"Chan Chee Seng, Keynote Speaker Prof James Lander and Yours President Prof Tan Eng Chai, Deputy President of Academic Affairs and Provost, Prof Aren't and Distinguished Guest, Alumni and Partners Here are Nurses and tuning in online Welcome to future works to point to the second edition of the nus lifelong learning festival.\",\n",
       " 'My name is jawi and a proud ulama staff member of nus and ummc for this morning.',\n",
       " 'The theme for this years conference is a infection and we are grateful that so many industry leaders and experts have the general sale of their time today to share their invaluable experiences in this area.',\n",
       " 'We are so grateful that you have taken the time to attend the conference and we hope that you will live with the insights connections and inspiration for our future wife.',\n",
       " 'I.',\n",
       " 'Before we begin a quick safety and evacuation briefing.',\n",
       " 'In case of emergency Please evacuate to dxd behind the state.',\n",
       " 'Or at the back of the hall to the assembly earlier outside and do not enter the building and further instructions.',\n",
       " \"Now let's get started.\",\n",
       " 'We would like to invite NS President Prof Tan Eng Chai to give the Welcome Actress Thanks.',\n",
       " 'Detective for Education, Mr.',\n",
       " 'Chan Chuncheon, the Guest, Colleges Alumni and Friends.',\n",
       " 'Good morning and I bet you a warm welcome to the second edition of the nus lifelong learning table.',\n",
       " \"The theme for this year's learning Festival is future work to point zero i in action.\",\n",
       " 'The emphasis is on action.',\n",
       " 'Many of us have already heard much about what I can do as promise and as parrots may sound like a paradox but i is for real and in action.',\n",
       " 'Transforming Works and Industries today.',\n",
       " 'We will have the privilege of hearing from industry leaders on how they are using ai in their organizations with complex them to deploy.',\n",
       " 'The changes are as broad about and how They are bringing the workforce on this new ai journey.',\n",
       " 'We are in the watershed moment at the cap of ai revolution.',\n",
       " 'Some of US here to wave Grand Heroes will require similar period.',\n",
       " \"Nearly forty years ago where personal computers came to the workplace Putting the power of computing into individual hands replacing Panama, Paper Records and type writer's jacket or show later.\",\n",
       " 'The transformative power of the PC Worlds attached to a whole new level by the emergence of the internet.',\n",
       " 'Prank could granted with the advantage of New Technologies.',\n",
       " 'We must be open excited and innovative about the opportunities that new technologies can bring and us recognizes that eye is a game changer.',\n",
       " 'We are actively positioning ourselves to right the potential of ai On the Research Front.',\n",
       " 'We established the US a Institute in March.',\n",
       " 'This year and this brings together I Researchers from across the university to accelerate Frontier I research as well as to boost real World Impact.',\n",
       " 'They say Institut of Forster a vibrant ecosystem that promotes synergistic A research and applications as well as to grow the talent pool And to engage the Goverment excellence industry in Partnerships.',\n",
       " 'And this also in the areas of education Healthcare finance, Sustainability logistics magnet factoring and so on and so forth.',\n",
       " 'This institute will also conduct research on how to regulate And to safeguard Transparency and Accountability.',\n",
       " 'To address etika concerns and risk associated with I And us has also been proactive like guiding and encouraging The integration of aI In our teaching and Learning.',\n",
       " 'So in February twenty twenty last year end up and guess crafted end interim policy and this is a first of its scene Singapore institutions to provide guidance on staff uses of a while and also how to manage students use of a high end.',\n",
       " 'since the beginning of this year The center for training learning and technology has been offering a range of a workshops on topics such as using generative a for cost design question generation and assessments and use it as to form a community of practice and this is to exchange ideas Share resources promote best practices and also set community standards for the use of ai in teaching and learning.',\n",
       " \"So i choose also being rode out across various aspects of our penetration and operational work and use it as both generative ai of a platform for our us community using retrieval, augmented generation process and all model such as open ai ppt and Google jamani This platform helps our staff to get answers for and use specific questions such as quarry his own and us policies and and use it as also works department's to use a life to improve productivity across a wide range of use cases.\",\n",
       " 'For example, using ai to access pupils and as part of learning and development.',\n",
       " 'The office of human resources has work with faculty members to develop blended on the job training for US administrative staff in data literacy and I some pleased to share that close to five thousand admins staff have completed the first level of data literacy course as well as the first level of ai competency course.']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d6c78-a12f-4eda-a676-8d3fce39a38a",
   "metadata": {},
   "source": [
    "# Summarize this transcript \"&lt;srt file contents &gt;\".  In the summary, use very short sentences and do not use abbreviations and titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0344daf4-c866-432e-8766-9962a5b8c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_gpt_summary =  \"The transcript is from the opening of an event, likely a conference, where the host introduces key guests, \"+\\\n",
    "# \"including the Minister for Education, Chan Chun Seng, and other distinguished individuals like keynote speaker James Lander \"+\\\n",
    "# \"and National University of Singapore President Tan Eng Chai. \"+\\\n",
    "# \"The event is the second edition of the National University of Singapore Lifelong Learning Festival, with a focus on 'Artificial Intelligence in Action.' \"+\\\n",
    "# \"The National University of Singapore President emphasizes the transformative power of artificial intelligence, comparing it to the advent of personal  \"+\\\n",
    "# \"computers and the internet. He discusses the university's efforts in artificial intelligence research, including the establishment of an  \"+\\\n",
    "# \"artificial intelligence institute aimed at accelerating research and promoting real-world applications. The President also highlights initiatives  \"+\\\n",
    "# \"to integrate artificial intelligence into teaching, learning, and university operations, including staff training in artificial intelligence and  \"+\\\n",
    "# \"data literacy. The event is positioned as a critical moment in the artificial intelligence revolution, urging participants to embrace and innovate  \"+\\\n",
    "# \"with new technologies.\"\n",
    "\n",
    "chat_gpt_summary = \"The speaker welcomes the audience. \"+\\\n",
    "\"The event is the NUS Lifelong Learning Festival. \"+\\\n",
    "\"The theme is AI in action. The focus is on how AI is transforming industries and work. \"+\\\n",
    "\"NUS has started an AI institute to advance research and partnerships. The institute also addresses \"+\\\n",
    "\"ethical concerns. NUS is using AI in teaching, learning, and administration. \"+\\\n",
    "\"Workshops guide staff and students on AI use. Around 5,000 staff completed courses in data literacy and AI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ea59526a-5f89-47f5-bc67-9b0fbfc17ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_summary_sentences = []\n",
    "\n",
    "for sentence in chat_gpt_summary.split(\".\"):\n",
    "    chatgpt_summary_sentences.append(sentence.strip()+\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9f23cbf6-9374-4a81-8f6e-2392a781e3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The speaker welcomes the audience.',\n",
       " 'The event is the NUS Lifelong Learning Festival.',\n",
       " 'The theme is AI in action.',\n",
       " 'The focus is on how AI is transforming industries and work.',\n",
       " 'NUS has started an AI institute to advance research and partnerships.',\n",
       " 'The institute also addresses ethical concerns.',\n",
       " 'NUS is using AI in teaching, learning, and administration.',\n",
       " 'Workshops guide staff and students on AI use.',\n",
       " 'Around 5,000 staff completed courses in data literacy and AI.']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_summary_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd366a05-52bb-4e4c-94a4-9849c86a0477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cbb697-1e70-4d39-9bdc-bee22a35a2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9576e97b-1b1b-44ea-95f9-391b32fce285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find time lengths\n",
    "\n",
    "with open(\"NUS-FutureWork-first10.json\") as f:\n",
    "    speechmatic_json = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f4535b26-7a2d-4905-8976-f0354dcdd321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # One way - Needs more work\n",
    "\n",
    "# time_segs = []\n",
    "# for word_ind, word in enumerate(speechmatic_json['results']):\n",
    "#     if 'is_eos' in word and word['is_eos']:\n",
    "#         time_segs.append(word['end_time'] - word['start_time'])\n",
    "# len(time_segs), len(final_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "65ecb4a8-6311-444c-8ffe-61708d3b4214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please put your hand to | Mr\n",
      "9.83 10.31\n",
      "1 ----\n",
      "Chan Chun Seang A very | Mr\n",
      "15.89 16.28\n",
      "2 ----\n",
      "Chan Chee Seng , Keynote | festival\n",
      "68.47 68.71\n",
      "3 ----\n",
      "My name is jawi and | morning\n",
      "92.59 92.8\n",
      "4 ----\n",
      "The theme for this years | area\n",
      "99.37 99.52\n",
      "5 ----\n",
      "We are so grateful that | wife\n",
      "113.59 113.77\n",
      "6 ----\n",
      "Before we begin a quick | briefing\n",
      "124.72 125.05\n",
      "8 ----\n",
      "In case of emergency Please | state\n",
      "128.71 128.86\n",
      "9 ----\n",
      "Or at the back of | instructions\n",
      "134.32 134.47\n",
      "10 ----\n",
      "We would like to invite | Thanks\n",
      "144.04 144.13\n",
      "12 ----\n",
      "Chan Chuncheon , the Guest | Friends\n",
      "168.4 168.64\n",
      "14 ----\n",
      "Good morning and I bet | table\n",
      "173.44 173.62\n",
      "15 ----\n",
      "The theme for this year's | action\n",
      "184.14 184.29\n",
      "16 ----\n",
      "Many of us have already | action\n",
      "195.58 195.88\n",
      "18 ----\n",
      "We will have the privilege | deploy\n",
      "213.97 214.18\n",
      "20 ----\n",
      "The changes are as broad | journey\n",
      "227.29 227.47\n",
      "21 ----\n",
      "We are in the watershed | revolution\n",
      "237.76 237.91\n",
      "22 ----\n",
      "Some of US here to | period\n",
      "244.57 244.93\n",
      "23 ----\n",
      "Nearly forty years ago where | later\n",
      "250.92 251.22\n",
      "24 ----\n",
      "The transformative power of the | internet\n",
      "269.7 269.94\n",
      "25 ----\n",
      "Prank could granted with the | Technologies\n",
      "280.02 280.2\n",
      "26 ----\n",
      "We must be open excited | changer\n",
      "284.1 284.31\n",
      "27 ----\n",
      "We are actively positioning ourselves | Front\n",
      "299.64 299.85\n",
      "28 ----\n",
      "We established the US a | March\n",
      "309.98 310.16\n",
      "29 ----\n",
      "This year and this brings | Impact\n",
      "314.54 314.84\n",
      "30 ----\n",
      "They say Institut of Forster | Partnerships\n",
      "329.93 330.11\n",
      "31 ----\n",
      "And this also in the | forth\n",
      "349.85 350.06\n",
      "32 ----\n",
      "This institute will also conduct | Accountability\n",
      "362.69 362.96\n",
      "33 ----\n",
      "To address etika concerns and | Learning\n",
      "373.81 373.99\n",
      "34 ----\n",
      "So in February twenty twenty | end\n",
      "392.44 392.68\n",
      "35 ----\n",
      "since the beginning of this | learning\n",
      "416.59 416.89\n",
      "36 ----\n",
      "So i choose also being | cases\n",
      "458.81 458.99\n",
      "37 ----\n",
      "For example , using ai | development\n",
      "512.12 512.33\n",
      "38 ----\n",
      "The office of human resources | course\n",
      "521.18 521.42\n",
      "39 ----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34, 34)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_times = []\n",
    "end_times = []\n",
    "time_segs = []\n",
    "final_timed_sentences = []\n",
    "cnt = 0\n",
    "for ind, final_sentence in enumerate(final_sentences):\n",
    "    final_sentence_tokens = []\n",
    "    start_time = 0\n",
    "    end_time = 0\n",
    "    for final_sentence_token in final_sentence.split(' '):\n",
    "        if final_sentence_token.endswith(','):\n",
    "            final_sentence_tokens.append(final_sentence_token.replace(',',''))\n",
    "            final_sentence_tokens.append(',') #separate comma token\n",
    "        else:\n",
    "            final_sentence_tokens.append(final_sentence_token)\n",
    "        \n",
    "    # for tk in final_sentence_tokens:\n",
    "    if len(final_sentence_tokens) > 5:\n",
    "        print(final_sentence_tokens[0], final_sentence_tokens[1], final_sentence_tokens[2], final_sentence_tokens[3], final_sentence_tokens[4],'|', final_sentence_tokens[-1].split('.')[0])\n",
    "        for word_ind, word in enumerate(speechmatic_json['results']):\n",
    "            if word['alternatives'][0]['content'].lower() == final_sentence_tokens[0].lower() and \\\n",
    "                speechmatic_json['results'][word_ind+1]['alternatives'][0]['content'].lower() == final_sentence_tokens[1].lower() and \\\n",
    "                speechmatic_json['results'][word_ind+2]['alternatives'][0]['content'].lower() == final_sentence_tokens[2].lower() and \\\n",
    "                speechmatic_json['results'][word_ind+3]['alternatives'][0]['content'].lower() == final_sentence_tokens[3].lower() and \\\n",
    "                speechmatic_json['results'][word_ind+4]['alternatives'][0]['content'].lower() == final_sentence_tokens[4].lower():\n",
    "                print(word['start_time'], word['end_time'])\n",
    "                time_segs.append(word['end_time'] - word['start_time'])\n",
    "                final_timed_sentences.append(final_sentence)\n",
    "                start_times.append(word['start_time'])\n",
    "                end_times.append(word['end_time'])\n",
    "        print(ind, '----')\n",
    "len(time_segs), len(final_timed_sentences)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ce6e26e7-2b47-4a44-86ec-d0c29871a66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4800000000000004 Please put your hand to gather to welcome all guest of owner Minister for education Mr.\n",
      "0.39000000000000057 Chan Chun Seang A very good morning to gasthof owner Minister for education, Mr.\n",
      "0.23999999999999488 Chan Chee Seng, Keynote Speaker Prof James Lander and Yours President Prof Tan Eng Chai, Deputy President of Academic Affairs and Provost, Prof Aren't and Distinguished Guest, Alumni and Partners Here are Nurses and tuning in online Welcome to future works to point to the second edition of the nus lifelong learning festival.\n",
      "0.20999999999999375 My name is jawi and a proud ulama staff member of nus and ummc for this morning.\n",
      "0.14999999999999147 The theme for this years conference is a infection and we are grateful that so many industry leaders and experts have the general sale of their time today to share their invaluable experiences in this area.\n",
      "0.1799999999999926 We are so grateful that you have taken the time to attend the conference and we hope that you will live with the insights connections and inspiration for our future wife.\n",
      "0.3299999999999983 Before we begin a quick safety and evacuation briefing.\n",
      "0.15000000000000568 In case of emergency Please evacuate to dxd behind the state.\n",
      "0.15000000000000568 Or at the back of the hall to the assembly earlier outside and do not enter the building and further instructions.\n",
      "0.09000000000000341 We would like to invite NS President Prof Tan Eng Chai to give the Welcome Actress Thanks.\n",
      "0.23999999999998067 Chan Chuncheon, the Guest, Colleges Alumni and Friends.\n",
      "0.18000000000000682 Good morning and I bet you a warm welcome to the second edition of the nus lifelong learning table.\n",
      "0.15000000000000568 The theme for this year's learning Festival is future work to point zero i in action.\n",
      "0.29999999999998295 Many of us have already heard much about what I can do as promise and as parrots may sound like a paradox but i is for real and in action.\n",
      "0.21000000000000796 We will have the privilege of hearing from industry leaders on how they are using ai in their organizations with complex them to deploy.\n",
      "0.18000000000000682 The changes are as broad about and how They are bringing the workforce on this new ai journey.\n",
      "0.15000000000000568 We are in the watershed moment at the cap of ai revolution.\n",
      "0.36000000000001364 Some of US here to wave Grand Heroes will require similar period.\n",
      "0.30000000000001137 Nearly forty years ago where personal computers came to the workplace Putting the power of computing into individual hands replacing Panama, Paper Records and type writer's jacket or show later.\n",
      "0.2400000000000091 The transformative power of the PC Worlds attached to a whole new level by the emergence of the internet.\n",
      "0.18000000000000682 Prank could granted with the advantage of New Technologies.\n",
      "0.20999999999997954 We must be open excited and innovative about the opportunities that new technologies can bring and us recognizes that eye is a game changer.\n",
      "0.21000000000003638 We are actively positioning ourselves to right the potential of ai On the Research Front.\n",
      "0.18000000000000682 We established the US a Institute in March.\n",
      "0.2999999999999545 This year and this brings together I Researchers from across the university to accelerate Frontier I research as well as to boost real World Impact.\n",
      "0.18000000000000682 They say Institut of Forster a vibrant ecosystem that promotes synergistic A research and applications as well as to grow the talent pool And to engage the Goverment excellence industry in Partnerships.\n",
      "0.20999999999997954 And this also in the areas of education Healthcare finance, Sustainability logistics magnet factoring and so on and so forth.\n",
      "0.2699999999999818 This institute will also conduct research on how to regulate And to safeguard Transparency and Accountability.\n",
      "0.18000000000000682 To address etika concerns and risk associated with I And us has also been proactive like guiding and encouraging The integration of aI In our teaching and Learning.\n",
      "0.2400000000000091 So in February twenty twenty last year end up and guess crafted end interim policy and this is a first of its scene Singapore institutions to provide guidance on staff uses of a while and also how to manage students use of a high end.\n",
      "0.30000000000001137 since the beginning of this year The center for training learning and technology has been offering a range of a workshops on topics such as using generative a for cost design question generation and assessments and use it as to form a community of practice and this is to exchange ideas Share resources promote best practices and also set community standards for the use of ai in teaching and learning.\n",
      "0.18000000000000682 So i choose also being rode out across various aspects of our penetration and operational work and use it as both generative ai of a platform for our us community using retrieval, augmented generation process and all model such as open ai ppt and Google jamani This platform helps our staff to get answers for and use specific questions such as quarry his own and us policies and and use it as also works department's to use a life to improve productivity across a wide range of use cases.\n",
      "0.21000000000003638 For example, using ai to access pupils and as part of learning and development.\n",
      "0.2400000000000091 The office of human resources has work with faculty members to develop blended on the job training for US administrative staff in data literacy and I some pleased to share that close to five thousand admins staff have completed the first level of data literacy course as well as the first level of ai competency course.\n"
     ]
    }
   ],
   "source": [
    "for sent_ind, sent in enumerate(final_timed_sentences):\n",
    "    print(time_segs[sent_ind], sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de0dcd-6cfc-4f7e-b4f8-279597251a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c9e42-fae7-41ab-86bc-dff53788c673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "063769d9-6f50-4df4-b0d8-13120d801b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "25d2efee-497e-4bfa-8bc9-d36657e9585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_embeddings = model.encode(chatgpt_summary_sentences)\n",
    "final_sentences_embeddings = model.encode(final_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0d4ff4a0-9eea-400d-bc6d-0c78a1613f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = model.similarity(chatgpt_embeddings, final_sentences_embeddings) # Not used\n",
    "\n",
    "\n",
    "cos = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "cos_similarities = []\n",
    "for chatgpt_embedding in chatgpt_embeddings:\n",
    "    chatgpt_sim = []\n",
    "    for final_sentences_embedding in final_sentences_embeddings:\n",
    "        chatgpt_sim.append(cos(torch.from_numpy(chatgpt_embedding), torch.from_numpy(final_sentences_embedding)).numpy())\n",
    "    cos_similarities.append(chatgpt_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0878e0bf-1826-4f0d-ba7b-2620ae7b6c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speaker welcomes the audience. ==> We would like to invite NS President Prof Tan Eng Chai to give the Welcome Actress Thanks.\n",
      "--------\n",
      "The event is the NUS Lifelong Learning Festival. ==> The theme for this year's learning Festival is future work to point zero i in action.\n",
      "--------\n",
      "The theme is AI in action. ==> We are actively positioning ourselves to right the potential of ai On the Research Front.\n",
      "--------\n",
      "The focus is on how AI is transforming industries and work. ==> The changes are as broad about and how They are bringing the workforce on this new ai journey.\n",
      "--------\n",
      "NUS has started an AI institute to advance research and partnerships. ==> We are actively positioning ourselves to right the potential of ai On the Research Front.\n",
      "--------\n",
      "The institute also addresses ethical concerns. ==> This institute will also conduct research on how to regulate And to safeguard Transparency and Accountability.\n",
      "--------\n",
      "NUS is using AI in teaching, learning, and administration. ==> For example, using ai to access pupils and as part of learning and development.\n",
      "--------\n",
      "Workshops guide staff and students on AI use. ==> For example, using ai to access pupils and as part of learning and development.\n",
      "--------\n",
      "Around 5,000 staff completed courses in data literacy and AI. ==> The office of human resources has work with faculty members to develop blended on the job training for US administrative staff in data literacy and I some pleased to share that close to five thousand admins staff have completed the first level of data literacy course as well as the first level of ai competency course.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(chatgpt_summary_sentences)):\n",
    "    print(chatgpt_summary_sentences[i], '==>', final_sentences[np.argmax(cos_similarities[i])])\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e01832e6-c2d1-45a8-ac0c-0fdc3a11550e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ladies and gentlemen.',\n",
       " 'Please put your hand to gather to welcome all guest of owner Minister for education Mr.',\n",
       " 'Chan Chun Seang A very good morning to gasthof owner Minister for education, Mr.',\n",
       " \"Chan Chee Seng, Keynote Speaker Prof James Lander and Yours President Prof Tan Eng Chai, Deputy President of Academic Affairs and Provost, Prof Aren't and Distinguished Guest, Alumni and Partners Here are Nurses and tuning in online Welcome to future works to point to the second edition of the nus lifelong learning festival.\",\n",
       " 'My name is jawi and a proud ulama staff member of nus and ummc for this morning.',\n",
       " 'The theme for this years conference is a infection and we are grateful that so many industry leaders and experts have the general sale of their time today to share their invaluable experiences in this area.',\n",
       " 'We are so grateful that you have taken the time to attend the conference and we hope that you will live with the insights connections and inspiration for our future wife.',\n",
       " 'I.',\n",
       " 'Before we begin a quick safety and evacuation briefing.',\n",
       " 'In case of emergency Please evacuate to dxd behind the state.',\n",
       " 'Or at the back of the hall to the assembly earlier outside and do not enter the building and further instructions.',\n",
       " \"Now let's get started.\",\n",
       " 'We would like to invite NS President Prof Tan Eng Chai to give the Welcome Actress Thanks.',\n",
       " 'Detective for Education, Mr.',\n",
       " 'Chan Chuncheon, the Guest, Colleges Alumni and Friends.',\n",
       " 'Good morning and I bet you a warm welcome to the second edition of the nus lifelong learning table.',\n",
       " \"The theme for this year's learning Festival is future work to point zero i in action.\",\n",
       " 'The emphasis is on action.',\n",
       " 'Many of us have already heard much about what I can do as promise and as parrots may sound like a paradox but i is for real and in action.',\n",
       " 'Transforming Works and Industries today.',\n",
       " 'We will have the privilege of hearing from industry leaders on how they are using ai in their organizations with complex them to deploy.',\n",
       " 'The changes are as broad about and how They are bringing the workforce on this new ai journey.',\n",
       " 'We are in the watershed moment at the cap of ai revolution.',\n",
       " 'Some of US here to wave Grand Heroes will require similar period.',\n",
       " \"Nearly forty years ago where personal computers came to the workplace Putting the power of computing into individual hands replacing Panama, Paper Records and type writer's jacket or show later.\",\n",
       " 'The transformative power of the PC Worlds attached to a whole new level by the emergence of the internet.',\n",
       " 'Prank could granted with the advantage of New Technologies.',\n",
       " 'We must be open excited and innovative about the opportunities that new technologies can bring and us recognizes that eye is a game changer.',\n",
       " 'We are actively positioning ourselves to right the potential of ai On the Research Front.',\n",
       " 'We established the US a Institute in March.',\n",
       " 'This year and this brings together I Researchers from across the university to accelerate Frontier I research as well as to boost real World Impact.',\n",
       " 'They say Institut of Forster a vibrant ecosystem that promotes synergistic A research and applications as well as to grow the talent pool And to engage the Goverment excellence industry in Partnerships.',\n",
       " 'And this also in the areas of education Healthcare finance, Sustainability logistics magnet factoring and so on and so forth.',\n",
       " 'This institute will also conduct research on how to regulate And to safeguard Transparency and Accountability.',\n",
       " 'To address etika concerns and risk associated with I And us has also been proactive like guiding and encouraging The integration of aI In our teaching and Learning.',\n",
       " 'So in February twenty twenty last year end up and guess crafted end interim policy and this is a first of its scene Singapore institutions to provide guidance on staff uses of a while and also how to manage students use of a high end.',\n",
       " 'since the beginning of this year The center for training learning and technology has been offering a range of a workshops on topics such as using generative a for cost design question generation and assessments and use it as to form a community of practice and this is to exchange ideas Share resources promote best practices and also set community standards for the use of ai in teaching and learning.',\n",
       " \"So i choose also being rode out across various aspects of our penetration and operational work and use it as both generative ai of a platform for our us community using retrieval, augmented generation process and all model such as open ai ppt and Google jamani This platform helps our staff to get answers for and use specific questions such as quarry his own and us policies and and use it as also works department's to use a life to improve productivity across a wide range of use cases.\",\n",
       " 'For example, using ai to access pupils and as part of learning and development.',\n",
       " 'The office of human resources has work with faculty members to develop blended on the job training for US administrative staff in data literacy and I some pleased to share that close to five thousand admins staff have completed the first level of data literacy course as well as the first level of ai competency course.']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b4415692-1a9c-45e9-9b07-ee63d00ba087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c79a5a52-1f2f-4dda-8e6c-bd4cc7eab8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff5662-40b9-4dea-ab61-bffa8e1cf816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c125b-3920-4882-b1e4-50b445d2997c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e2bae5-d73f-4b9e-be5b-de1fb46852e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4d1308ac-1b56-4665-9a47-649762426a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7f5d60d3-819f-4b39-89cb-96790ea46c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speechmatic_json['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf449a-3523-46b5-9b63-e606d81f2987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7abeea2-bf14-4e10-b9ef-c0f842bd9e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371d8a0-d7fa-4287-9d37-6c52650564b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video-summaries",
   "language": "python",
   "name": "video-summaries"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
